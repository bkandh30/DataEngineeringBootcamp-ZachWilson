# OBSIDIAN'S KPI AND EXPERIMENTATION

I am going to discuss about Obsidian. I have used Obsidian for a significant period, and it has become an essential tool for my personal knowledge management and note-taking needs. Initially, I was drawn to Obsidian due to its local-first approach, markdown-based system, and powerful linking capabilities. Unlike other note-taking apps, Obsidian allowed me to structure my knowledge dynamically, making it easier to connect ideas and revisit them later.

The first few weeks of using Obsidian were focused on basic note-taking. However, as I explored its plugin ecosystem, I started using features like graph view, backlinks, and community plugins that enhanced my workflow. Over time, my use of Obsidian evolved into a structured personal knowledge management system, with daily notes, linked references, and a more organized way of handling information.

For this reason, I am going to run 3 experiments to keep me engaged with Obsidian and improve its user experience.

## Experiment 1: AI-Powered Note Suggestions vs. Tag-Based Search

**Objective:** Users often struggle with retrieving relevant notes quickly. This experiment aims to determine whether AI-powered note suggestions improve note retrieval and knowledge discovery compared to the traditional tag-based search system.

**Null Hypothesis:** The AI-powered note suggestion system does not significantly improve user efficiency and note retrieval experience compared to tag-based search.

**Alternative Hypothesis:** Users utilizing AI-powered note suggestions retrieve information faster and interact with more relevant notes compared to those using tag-based search.

**Leading Metric:** Reduction in time taken to find relevant notes; increase in the number of relevant notes accessed per session.

**Lagging Metric:** User satisfaction based on post-experiment surveys; retention rate of users engaging with AI-powered suggestions.

**Test cell allocation:** 50%-50%

## Experiment 2: Improving Markdown Table Creation

**Objective:** Creating tables in Markdown is a cumbersome process. This experiment aims to determine whether a OneNote-style table editor improves the note-taking experience compared to the current Markdown-based approach.

**Null Hypothesis:** The addition of a OneNote-style table editor does not significantly impact user satisfaction or note usability compared to the current Markdown-based table creation.

**Alternative Hypothesis:** Users with access to an improved table editor experience higher satisfaction, increased table usage, and greater efficiency in organizing structured information.

**Leading Metric:** Increase in table creation frequency; decrease in time taken to create and edit tables.

**Lagging Metric:** Higher user satisfaction ratings; increased adoption of table-based notes over time.

**Test cell allocation:** 50%-50%

## Experiment 3: Improving Mobile App Performance

**Objective:** Users on iPhones often experience slow performance and crashes when switching between Vaults. This experiment aims to determine whether optimizing the mobile app's performance leads to a better user experience and reduced frustration.

**Null Hypothesis:** Performance optimizations do not significantly reduce app crashes or improve loading speed on iPhones.

**Alternative Hypothesis:** Performance optimizations lead to faster app load times, smoother Vault switching, and a decrease in app crashes on iPhones.

**Leading Metric:** Reduction in app crash reports; decrease in load time when opening the app and switching Vaults.

**Lagging Metric:** Increase in user retention for iPhone users; higher app store ratings and user satisfaction scores.

**Test cell allocation:** 50%-50%
